---
title: "STAT 331 Portfolio"
author: "Miriam Rosen"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r}
#| label: wd-1-csv

surveys <- read_csv(here("data", "surveys.csv"))

# This code is from lab 2, question 1.

```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

agesxl <- read_xlsx(path = here::here("check-ins", "2.1-loading-data", "Ages_Data", "ages.xlsx"), sheet = "ages")

# This code is from Check-in 2.3.

```

-   `txt`

```{r}
#| label: wd-1-txt

ages_tab <- read_table(file = here::here("Week 2", "Check-ins", "Ages_Data", "ages_tab.txt"))


# This code is from Check-in 2.3.


```

**WD-2: I can select necessary columns from a dataset.**

```{r}
#| label: wd-2

teacher_evals_clean <- teacher_evals |> 
  rename(sex = gender) |> 
  filter(no_participants > 10) |> 
  mutate(teacher_id  = as.character(teacher_id)) |>
  select(course_id, 
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
        )

# This code is from lab 3, question 5.

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r}
#| label: wd-3-numeric

teacher_evals_clean <- teacher_evals |> 
  rename(sex = gender) |> 
  filter(no_participants > 10) |> 
  mutate(teacher_id  = as.character(teacher_id)) |>
  select(course_id, 
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
        )

# This code is from lab 3, question 5.

```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

witnesses <- bind_rows(person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            ), 
  person |> 
  mutate(is_annabel = str_detect(name,
                                 "^Annabel"
                                 )
         ) |>
  filter(address_street_name == "Franklin Ave",
         is_annabel
          )
  )

# This code is from lab 5, section 2: Finding Witnesses.

```

-   factor

```{r}
#| label: wd-3-factor

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

# This code is from lab 4, question 2.

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

suspect <- person |>
  inner_join(drivers_license,
             join_by(license_id == id)) |>
  inner_join(facebook_event_checkin,
             join_by(id == person_id)) |>
  mutate(concert_month = month(ymd(date))) |>
  filter(gender == "female",
         height %in% c("65","66",
                        "67"
                        ),
         hair_color == "red",
         car_model == "Model S",
         car_make == "Tesla", 
         event_name == "SQL Symphony Concert",
         concert_month == 12,
         year(ymd(date)) == 2017
         ) |> 
  group_by(id, name) |> 
  summarize(event_name = n(), 
            .groups = "drop"
            ) |> 
  filter(event_name == 3) |>
  print()


# This code is from lab 5, section 6: Finding Person Responsible.

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

```{r}
#| label: wd-4-numeric

teacher_evals |> 
  filter(question_no == 903) |> 
  mutate(SET_level = if_else(SET_score_avg >= 4,
                             "excellent",
                             "standard"
                             ), 
         sen_level = if_else(seniority <= 4,
                              "junior",
                              "senior"
                              )
          
         ) |>
  select(course_id, 
         SET_level, 
         sen_level
         )

# This code is from challenge 3, question 1.

```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

witnesses <- bind_rows(person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            ), 
  person |> 
  mutate(is_annabel = str_detect(name,
                                 "^Annabel"
                                 )
         ) |>
  filter(address_street_name == "Franklin Ave",
         is_annabel
          )
  )
      
# This code is from lab 5, section 2: Finding Witnesses.

```

-   factor (example must use functions from **forcats**)

```{r}
#| label: wd-4-factor

ca_childcare <- ca_childcare |> 
 mutate(county_name = str_remove(county_name, " County")) |>
  mutate(region = fct_collapse(county_name,
                               "Superior California" = c("Butte",
                                                         "Colusa",
                                                         "El Dorado",
                                                         "Glenn", 
                                                         "Lassen", 
                                                         "Modoc",
                                                         "Nevada",
                                                         "Placer", 
                                                         "Plumas", 
                                                         "Sacramento", 
                                                         "Shasta", 
                                                         "Sierra", 
                                                         "Siskiyou",
                                                         "Sutter", 
                                                         "Tehama", 
                                                         "Yolo",
                                                         "Yuba"
                                                         ),
                               "North Coast" = c("Del Norte",
                                                 "Humboldt",
                                                 "Lake",
                                                 "Mendocino", 
                                                 "Napa", "Sonoma", 
                                                 "Trinity"
                                                 ),
                               "San Francisco Bay Area" = c("Alameda", 
                                                            "Contra Costa", 
                                                            "Marin", 
                                                            "San Francisco", 
                                                            "San Mateo", 
                                                            "Santa Clara",
                                                            "Solano"
                                                            ),
                               "Northern San Joaquin Valley" = c("Alpine", 
                                                                 "Amador", 
                                                                 "Calaveras",
                                                                 "Madera",
                                                                 "Mariposa",
                                                                 "Merced", 
                                                                 "Mono", 
                                                                 "San Joaquin", "Stanislaus", 
                                                                 "Tuolumne"
                                                                ),
                               "Central Coast" = c("Monterey",
                                                   "San Benito",
                                                   "San Luis Obispo",
                                                   "Santa Barbara",
                                                   "Santa Cruz",
                                                   "Ventura"
                                                   ),
                               "Southern San Joaquin Valley" = c("Fresno",
                                                                 "Inyo",
                                                                 "Kern",
                                                                 "Kings",
                                                                 "Tulare"
                                                                 ),
                               "Inland Empire" = c("Riverside",
                                                   "San Bernardino"
                                                         ),
                               "Los Angeles County" = c("Los Angeles"),
                               "Orange County" = c("Orange"),
                               "San Diego - Imperial" = c("San Diego",
                                                    "Imperial"
                                                    )
                               )
         ) 

# This code is from lab 4, question 3.

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

suspect <- person |>
  inner_join(drivers_license,
             join_by(license_id == id)) |>
  inner_join(facebook_event_checkin,
             join_by(id == person_id)) |>
  mutate(concert_month = month(ymd(date))) |>
  filter(gender == "female",
         height %in% c("65","66",
                        "67"
                        ),
         hair_color == "red",
         car_model == "Model S",
         car_make == "Tesla", 
         event_name == "SQL Symphony Concert",
         concert_month == 12,
         year(ymd(date)) == 2017
         ) |> 
  group_by(id, name) |> 
  summarize(event_name = n(), 
            .groups = "drop"
            ) |> 
  filter(event_name == 3) |>
  print()


# This code is from lab 5, section 6: Finding Person Responsible.

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r}
#| label: wd-5-left

get_fit_now_member |> 
  filter(membership_status == "gold",
         str_detect(id,
                   "48Z"
                   )
         ) |>
  left_join(get_fit_now_check_in,
             by = c("id" = "membership_id"
                     )
              ) |>
  mutate(check_in_date = ymd(check_in_date)) |>
  filter(check_in_date == ymd("2018-01-09")) |>  
  left_join(person, 
            by = c("person_id" = "id"
                   ) 
         ) |> 
  left_join(drivers_license,
            by = c("license_id" = "id"
                   )
            ) |>
  filter(str_detect(plate_number,
                      "H42W"
                  )
          )

# This code is from lab 5, section 4: Using Witness's Clues. Although using the inner_join() function would be more efficient, using the left_join() function still achieves the same result. The inner_join() function is more effective because it retain rows where there is a match between the keys in both datasets. When using the left_join() function, all of the rows from the left dataset are kept, meaning that if there are unmatched rows in the right dataset, there will be rows with NA cells. This leads the resulting joined dataset to potentially have irrelevant observations and be less clean than if the inner_join() function was used.

```

-   `right_join()`

```{r}
#| label: wd-5-right

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

# This code is from lab 4, question 2.

```

-   `inner_join()`

```{r}
#| label: wd-5-inner

get_fit_now_member |> 
  filter(membership_status == "gold",
         str_detect(id,
                   "48Z"
                   )
         ) |>
  inner_join(get_fit_now_check_in,
             by = c("id" = "membership_id"
                     )
              ) |>
  mutate(check_in_date = ymd(check_in_date)) |>
  filter(check_in_date == ymd("2018-01-09")) |>  
  inner_join(person, 
            by = c("person_id" = "id"
                   ) 
         ) |> 
  inner_join(drivers_license,
            by = c("license_id" = "id"
                   )
            ) |>
  filter(str_detect(plate_number,
                      "H42W"
                  )
          )


# This code is from lab 5, section 4: Using Witness's Clues. I originally used left_join(), which works to combine the data sets, but includes NA's when the second dataset does not have a matching row. For this task, using the inner_join() function is more effective because it only retains rows with matching data, aligning better with the goal of this task to narrow down the datasets to a single row based on the specified factors in the code. 

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

interview |> 
    semi_join(witnesses, 
            by = c("person_id" = "id")
            )

# This code is from lab 5, section 3: Examining Witness Interviews.

```

-   `anti_join()`

```{r}
#| label: wd-6-anti


degrees_not <- tibble(academic_degree = c("no_dgr", "ma"))

teacher_evals_clean |> 
  anti_join(degrees_not,
            by = "academic_degree"
            ) |>
  filter(sex == "female") |>
  group_by(teacher_id) |>
  summarise(average_response = mean(resp_share,
                                    na.rm = TRUE
                                    ),
            .groups = 'drop'
            ) |>
  mutate(max_values = max(average_response),
         min_values = min(average_response)
         ) |> 
    filter(average_response == max_values | average_response == min_values) |> 
    arrange(average_response) |>
    select(teacher_id, 
           average_response
           ) |>
  print()

# This code is from lab 3, question 12. I originally used the filter() function in my original code to filter to include specific academic degrees. To utilize the anti_join() function, I created a tibble which included the two academic degrees that I did not want to have in my average responses. Then, I used the anti_join to join the teacher_evals_clean data set with the degrees_not data set to filter to only include academic degrees that do not have matches in the degrees_not data set. 


```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8, "Accent"))(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )


# This code is from lab 4, question 6.

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide


mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income,
              names_prefix = "Median Household Income in ") |> 
  arrange(desc(`Median Household Income in 2008`), 
          desc(`Median Household Income in 2018`)
          ) |>
  rename("Region" = region) |>
  print()

# This code is from lab 4, question 4. 

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

I have demonstrated this learning target throughout my lab assignments this quarter. Firstly, in the YAML of my quarto documents, I have incorporated various features to my rendered document such as code-folding and embedding resources, enhancing the professionalism of my rendered quarto documents. Secondly, I have made a conscious effort to write tidy code, adhering to the tidyverse style guidelines, using named arguments, and starting new lines after commas, plus signs, and pipe operators. Additionally, I have been thoughtful to ensure that my code is efficient, specifically using one function to perform multiple operations and calculating multiple summary statistics by using functions such as the summarize and across functions. One lab I am particularly proud of for its professional appearance is lab 5. In this lab, I formatted my own quarto document and included section headers to make clear sections for the viewer to be able to easily follow along. Lastly, I have learned how to use and implement the here function into my projects to load in data of various formats including csv, xlsx, and txt files.

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

# Initializing a plot using the dataset, teacher_evals_compare, with seniority level mapped to the x axis and SET level mapped to fill color. 
ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level, fill = SET_level)
       ) +
# Creating a stacked barplot to count observations
  geom_bar(stat = "count",
           position = "stack"
           ) + 
# Adding colors to the SET levels, excellent and standard
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                  ) +
# Adding a background theme
  theme_bw() +
# Adding labels to x axis, adding a title, and removing a label from the y axis to prevent viewers from having to tilt their heads 
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections"
       ) +
# Adding annotations on the bars to display the count of each SET_level category

  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
# Removes legend from visualization
  theme(legend.position = "none") 

# This code is from challenge 3, question 2. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2


# Selecting columns from the ca_childcare dataset  
mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
# Filtering the dataset to only include the years, 2008 and 2018
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
# Grouping the data by region and study_year 
  group_by(region, study_year) |>
# Calculating the median household income for each region in 2008 and 2018  
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
# Pivoting the data to a wider format, where each study year, 2008 and 2018, have their own column with the values in these two columns being the median household incomes for respective regions
  pivot_wider(names_from = study_year,
              values_from = median_household_income,
              # Adding a prefix to new columns for clarity 
              names_prefix = "Median Household Income in ") |>  
# Arranging the rows in descending order of median household income for 2008 and 2018
  arrange(desc(`Median Household Income in 2008`), 
          desc(`Median Household Income in 2018`)
          ) |>
# Renaming the region column to be capitalized for consistency in column names 
  rename("Region" = region) |>
# Printing the final table 
  print()

# This code is from lab 4, question 4.

```

-   Example of function formatting

```{r}
#| label: r-2-3

rescale_01 <- function(x) {
  # Checking if the input is a numeric vector and if the input is not numeric, stopping the function and returning an error message. 
  if (!is.numeric(x)) stop("Input vector must be numeric.")
  
  # Checking if the input vector has more than one element and if the input vector does not have more than one element, stopping the function and returning an error message. 
  if (length(x) <= 1) stop("Input vector requires more than one element.")
  
  # Calculating the range of the input vector 
  range_1 <- range(x,
        na.rm = TRUE
        )
  # Subtracting the minimumum value from the input vector and dividing by the difference between the maximum and minimum vale of the input vector to rescale the input vector to a 0-1 range
  (x - range_1[1]) / (range_1[2] - range_1[1])
}

# This code is from lab 7, question 4.

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

```{r}
#| label: r-3-example

person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            )

# This code is from lab 5, section 3: Examining Witness Interviews.

```

-   Example of function stops

```{r}
#| label: r-3-function-stops

rescale_01 <- function(x) {
  if(!is.numeric(x)) stop("Input vector must be numeric.")
  if(length(x) <= 1) stop("Input vector requires more than one element.")
  range_1 <- range(x,
        na.rm = TRUE
        )
  (x - range_1[1]) / (range_1[2] - range_1[1])
}

# This code is from lab 7, question 4.

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

```{r}
#| label: dvs-1-num

ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot
Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

# This code is from lab 2, question 4.

```

-   at least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat


ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot
Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

# This code is from lab 2, question 4.


```

-   at least two categorical variables

```{r}
#| label: dvs-2-cat

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level, fill = SET_level)
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 


# This code is from challenge 3, question 2. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

```

-   dates (timeseries plot)

```{r}
#| label: dvs-2-date

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8, "Accent"))(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

# This code is from lab 4, question 6.


```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

```{r}
#| label: dvs-2-1


ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot Length Across Different Rodent Species", 
       subtitle = "Length of Hindfoot (in mm)"
       )

# This code is from lab 2, question 4. 

```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-2

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8, "Accent"))(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

# This is from lab 4, question 6.

ggplot(data = ca_childcare, 
       mapping = aes(x = mhi_2018, 
                     y = mc_infant
                     )
       ) + 
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm",
              color = "steelblue"
              ) +
  labs(title = "Relationship Between Median Household Income and Median Weekly 
  Center-Based Chilcare Cost for an Infant in California",
       x = "Median Household Income (in U.S. dollars)", 
       y = ""
       ) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_dollar())

# This code is from lab 4, question 7.

```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-3

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8, "Accent"))(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

# This code is from lab 4, question 6. 

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

```{r}
#| label: dvs-3-1

library(ggridges)


  ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = species, 
        stat = "density_ridges",
        position = "points_sina",
        fill = species
                    )
       ) +
  geom_density_ridges() + 
  labs(x = "Weight (in grams)" , 
     y = "", 
     subtitle = "Species of Rodents",
     title = "Density Ridge Plots of Weights of Various Rodent Species") +
 scale_fill_manual(values = c("torridus" = "#c51b8a", 
                              "spectabilis" = "#fa9fb5", 
                              "penicillatus" = "#f03b20", 
                              "ordii" = "#feb24c", 
                              "merriami" = "#fff7bc", 
                              "megalotis" = "#edf8b1",
                              "maniculatus" =  "#a1d99b",
                              "leucogaster" = "#e5f5f9", 
                              "hispidus" = "#7fcdbb", 
                              "fulvescens" = "#2b8cbe", 
                              "flavus" = "#e7e1ef", 
                              "eremicus" = "#bcbddc", 
                              "baileyi" = "#756bb1", 
                              "albigula" = "#8856a7"
                              )
                   ) +
    theme(legend.position = "none")
  
# This code is from challenge 2, spicy. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level,
                     fill = SET_level
                     )
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 

# This code is from challenge 3, question 2. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 


ggplot(data = all_simulations,
         mapping = aes(x = simulated_means)
         ) + 
geom_histogram(color = "#756bb1",
                 fill = "#bcbddc"
                 ) + 
facet_wrap(~ n, 
             scales = "free_y", 
           labeller = labeller(n = c("10" = "10 Simulated Means", 
                                     "100" = "100 Simulated Means", 
                                     "1000" = "1,000 Simulated Means",
                                     "10000" = "10,000 Simulated Means"
                                     )
                               )
             ) +
labs(title = "Distribution of Simulated Means by Simulation Sizes", 
       y = "", 
       x = "Simulated Mean",
       subtitle = "Frequency"
       ) +
theme_bw() + 
theme_minimal()

# This code is from lab 9, question 8. I originally labelled each facet as "Sample Size of _" instead of "_ Simulated Means." I realize now that the plot is showing the distributions of simulated means from each of the simualtions, not the distribution of means based on sample size. It is important that I accurately label my facets to avoid misleading viewers, ensuring the data and information is interpreted correctly. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

```

-   I can use annotations

```{r}
#| label: dvs-3-2

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level, fill = SET_level)
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 


# This code is from challenge 3, question 2. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

```

-   I can be creative...

```{r}
#| label: dvs-3-3

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level, fill = SET_level)
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 

# This code is from challenge 3, question 2. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

teacher_evals_clean |> 
  summarize(courses = n_distinct(course_id), 
            instructors = n_distinct(teacher_id)
            )

# This code is from lab 3, question 6. 

```

-   Example using `across()`

```{r}
#| label: dvs-4-across

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

# This code is from lab 7, question 1

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

library(gt)

all_simulations |> 
  group_by(n) |> 
  summarize(mean = mean(simulated_means),
            .groups = "drop"
            ) |> 
  pivot_wider(id_cols = everything(), 
              names_from = n, 
              values_from = mean) |> 
  rename('Simulated Mean of 10' = '10',
         'Simulated Mean of 100' = '100', 
         'Simulated Mean of 1,000' = '1000',
         'Simulated Mean of 10,000' = '10000'
         ) |> 
  gt() |> 
  tab_header(title = "Simulated Means By Sample Size", 
             subtitle = "Exploration of Results Across Varying Sample Sizes"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body()
            )


# This code is from lab 9, question 7. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 


```

-   Example 2

```{r}
#| label: dvs-5-2

mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income,
              names_prefix = "Median Household Income in ") |> 
  arrange(desc(`Median Household Income in 2008`), 
          desc(`Median Household Income in 2018`)
          ) |>
  rename("Region" = region) |>
  print()

# This code is from lab 4, question 4

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r}
#| label: dvs-6-1

library(gt)

all_simulations |> 
  group_by(n) |> 
  summarize(mean = mean(simulated_means),
            .groups = "drop"
            ) |> 
  pivot_wider(id_cols = everything(), 
              names_from = n, 
              values_from = mean) |> 
  rename('Simulated Mean of 10 Means' = '10',
         'Simulated Mean of 100 Means' = '100', 
         'Simulated Mean of 1,000 Means' = '1000',
         'Simulated Mean of 10,000 Means' = '10000'
         ) |> 
  gt() |> 
  tab_header(title = "Simulated Mean of Means By Sample Size", 
             subtitle = "Exploration of Results Across Varying Sample Sizes"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body()
            )

# This code is from lab 9, question 7. I originally labeled the title "Simulated Means By Sample Size" instead of "Simulated Mean of Means By Sample Size" and each column, "Simulated Mean of __" instead of "Simulated Mean of __ Means." I now realize that this is not the simulated means but the simulated means of means. It is important that I correctly label all aspects of my table to ensure viewers correctly interpret my table and there are no misunderstandings about what the data represents. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 


```

-   Example 2

```{r}
#| label: dvs-6-2

library(gt)

tibble_of_results <- enframe(results, 
                             name = "simulation_number",
                             value = "ncorrect"
                             )

random_babies_table <- tibble_of_results |> 
  count(ncorrect, 
        name = "baby_count") |> 
  mutate(proportion = baby_count / sum(baby_count))

rotate_proportions <- random_babies_table |> 
  select(ncorrect, 
         proportion
         ) |> 
  pivot_wider(names_from = ncorrect, 
              values_from = proportion
                ) |>
  rename("0 Correct Matches" = "0",
         "1 Correct Match" = "1", 
         "2 Correct Matches" = "2", 
         "4 Correct Matches" = "4") |>
   gt() |> 
  tab_header(title = "Baby Matching Simulation Results", 
             subtitle = "Proportions of Correctly Matched Babies Across 10,000 Simulations"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body() 
            ) |>
  print()
 
# This code is from lab 9, question 2. I originally used the names_prefix() function to add a prefix to the names of my columns, but these names were not the strongest names to describe the context of the columns. Instead, I used the rename() function to add stronger descriptive names for each column. Originally, I also included both the counts and proportions. I removed the counts as this was unnecessary and redundant. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors.  

```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r}
#| label: dvs-7-1

library(gt)

tibble_of_results <- enframe(results, 
                             name = "simulation_number",
                             value = "ncorrect"
                             )

random_babies_table <- tibble_of_results |> 
  count(ncorrect, 
        name = "baby_count") |> 
  mutate(proportion = baby_count / sum(baby_count))

rotate_proportions <- random_babies_table |> 
  select(ncorrect, 
         proportion
         ) |> 
  pivot_wider(names_from = ncorrect, 
              values_from = proportion
                ) |>
  rename("0 Correct Matches" = "0",
         "1 Correct Match" = "1", 
         "2 Correct Matches" = "2", 
         "4 Correct Matches" = "4") |>
   gt() |> 
  tab_header(title = "Baby Matching Simulation Results", 
             subtitle = "Proportions of Correctly Matched Babies Across Simulations"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body() 
            ) |>
  print()
 
# This code is from lab 9, question 2. I originally used the names_prefix() function to add a prefix to the names of my columns, but these names were not the strongest names to describe the context of the columns. Instead, I used the rename() function to add stronger descriptive names for each column. Originally, I also included both the counts and proportions. I removed the counts as this was unnecessary and redundant. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors.   


```

-   Example 2

```{r}
#| label: dvs-7-2

library(gt)

all_simulations |> 
  group_by(n) |> 
  summarize(mean = mean(simulated_means),
            .groups = "drop"
            ) |> 
  pivot_wider(id_cols = everything(), 
              names_from = n, 
              values_from = mean) |> 
  rename('Simulated Mean of 10 Means' = '10',
         'Simulated Mean of 100 Means' = '100', 
         'Simulated Mean of 1,000 Means' = '1000',
         'Simulated Mean of 10,000 Means' = '10000'
         ) |> 
  gt() |> 
  tab_header(title = "Simulated Mean of Means By Sample Size", 
             subtitle = "Exploration of Results Across Varying Sample Sizes"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body()
            )

# This code is from lab 9, question 7. I originally labeled the title "Simulated Means By Sample Size" instead of "Simulated Mean of Means By Sample Size" and each column, "Simulated Mean of __" instead of "Simulated Mean of __ Means." I now realize that this is not the simulated means but the simulated means of means. It is important that I correctly label all aspects of my table to ensure viewers correctly interpret my table and there are no misunderstandings about what the data represents. I used https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3 to get my colors. 

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

crime_scene_report |> 
  mutate(date = ymd(date)) |> 
  filter(date == ymd("2018-01-15"), 
         type == "murder",
         city == "SQL City"
         )

# This code is from lab 5, section 1: Crime Scene Report.


```

-   `across()`

```{r}
#| label: pe-1-across

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

# This code is from lab 7, question 1.

```

-   `map()` functions

```{r}
#| label: pe-1-map-1

tibble(Variable = names(fish), 
       Missing = map_int(fish, 
                         ~ sum(is.na(.x)
                               )
                         )
       ) |> 
  rename(`Missing Amount` = Missing, 
         `Fish Attributes` = Variable) |>
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 15)

# This code is from lab 8, question 4.

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

```{r}
#| label: pe-2-1

rescale_01 <- function(x) {
  if(!is.numeric(x)) stop("Input vector must be numeric.")
  if(length(x) <= 1) stop("Input vector requires more than one element.")
  range_1 <- range(x,
        na.rm = TRUE
        )
  (x - range_1[1]) / (range_1[2] - range_1[1])
}

# This code is from lab 7, question 4


```

-   Function that operates on data frames

```{r}
#| label: pe-2-2

map_chr_func <- function(df){
  typ <- map_chr(df,
                 class
                 )
  tibble(
    Variable = names(df),
    Type = typ
    ) |> 
      pivot_wider(names_from = Variable, 
                  values_from = Type
                  )
  
 }
 
evals_1 <- map_chr_func(evals) |> 
  rename("Course ID" = "course_id", 
         "Teacher ID" = "teacher_id", 
         "Question Number" = "question_no",
         "Number of Participants" = "no_participants", 
         "Response Rate" = "resp_share", 
          "SET Score Average" = "SET_score_avg",
         "Student Grade Average" = "stud_grade_avg", 
         "Student Grade Standard Deviation" = "stud_grade_std",
         "Student Grade Variance Coefficient" = "stud_grade_var_coef", 
         "Percent Failed" = "percent_failed", 
         "Current Semester Student Grade Average" = "stud_grade_avg_cur", 
         "Current Semester Student Grade Standard Deviation" = "stud_grade_std_cur", 
         "Current Semester Student Grade Variance Coefficient" = "stud_grade_var_coef_cur", 
         "Current Semester Perecent Failed" = "percent_failed_cur",
         "Class Duration" = "class_duration", 
         "Weekday" = "weekday", 
         "Time of Day" = "time_of_day", 
         "SET Score of Teacher in Previous Semester" = "SET_score_1sem", 
         "Maximum Score" = "maximum_score", 
         "Academic Degree" = "academic_degree", 
         "Seniority" = "seniority", 
         "Gender" = "sex"
         ) |>
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 15) |>
  print()


# This code is from lab 8, question 1. Originally, I used the tibble() function outside of my function. While this worked, this could lead to redundancy, as I would have to rewrite the tibble() function everytime I wanted to create a tibble with the map_chr_func() function. By implemneting the tibble() function directly in my map_chr_func() function, I improved the efficiency and readaiblity of my code. This change can help prevent errors with manually rewriting the same code and creates a reusable function.  

```

**PE-3: I can use iteration to reduce repetition in my code.**

-   `across()`

```{r}
#| label: pe-3-across

rescale_column <- function(Df, cols) {
    if (!is.data.frame(Df)) {stop("The input 'Df' is not a dataframe.")
    }
    if (!all(cols %in% colnames(Df))) {stop("One or more of the columns in 'cols' are not in the given dataframe")
      }
   Df <- Df |> 
    mutate(across({{cols}},
                  rescale_01
                  )
           )
  return(Df)
}

# This code is from lab 7, question 8. 


```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

map_chr_func <- function(df){
  typ <- map_chr(df,
                 class
                 )
  tibble(
    Variable = names(df),
    Type = typ
    ) |> 
      pivot_wider(names_from = Variable, 
                  values_from = Type
                  )
  
 }
 
evals_1 <- map_chr_func(evals) |> 
  rename("Course ID" = "course_id", 
         "Teacher ID" = "teacher_id", 
         "Question Number" = "question_no",
         "Number of Participants" = "no_participants", 
         "Response Rate" = "resp_share", 
          "SET Score Average" = "SET_score_avg",
         "Student Grade Average" = "stud_grade_avg", 
         "Student Grade Standard Deviation" = "stud_grade_std",
         "Student Grade Variance Coefficient" = "stud_grade_var_coef", 
         "Percent Failed" = "percent_failed", 
         "Current Semester Student Grade Average" = "stud_grade_avg_cur", 
         "Current Semester Student Grade Standard Deviation" = "stud_grade_std_cur", 
         "Current Semester Student Grade Variance Coefficient" = "stud_grade_var_coef_cur", 
         "Current Semester Perecent Failed" = "percent_failed_cur",
         "Class Duration" = "class_duration", 
         "Weekday" = "weekday", 
         "Time of Day" = "time_of_day", 
         "SET Score of Teacher in Previous Semester" = "SET_score_1sem", 
         "Maximum Score" = "maximum_score", 
         "Academic Degree" = "academic_degree", 
         "Seniority" = "seniority", 
         "Gender" = "sex"
         ) |>
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 15) |>
  print()


# This code is from lab 8, question 1. Originally, I used the tibble() function outside of my function. While this worked, this could lead to redundancy, as I would have to rewrite the tibble() function everytime I wanted to create a tibble with the map_chr_func() function. By implemneting the tibble() function directly in my map_chr_func() function, I improved the efficiency and readaiblity of my code. This change can help prevent errors with manually rewriting the same code and creates a reusable function.  

```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

simulate_means <- function(n, df){
  map_dbl(.x = 1: n, 
          .f = ~rchisq(n = 100, df = df) %>% mean()
          )
}

grid <- crossing(n = c(10,
                       100,
                       1000,
                       10000
                       ), 
                 df = 10)

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, 
                                          df = df
                                          ), 
                                .f = simulate_means)
         ) |> 
  unnest(simulated_means) 

# This code is from lab 9, questions 4-6.

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

# This code is from lab 7, question 1

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8, "Accent"))(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

# This code is from lab 4, question 6


```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1 

randomBabies <- function(nBabies){
   babies <- tibble(baby = 1: nBabies, 
                    parent = sample(1: nBabies,
                                    size = nBabies,
                                    replace = FALSE
                                    )
   )         
  correct_baby_count <- sum(babies$baby == babies$parent)
  return(correct_baby_count)

}

results <- map_int(.x = 1:10000, 
                   .f = ~ randomBabies(nBabies = 4))

head(results)

# This code is from lab 9, question 1. Originally, I used $ operators to get correct_baby_count, but realized I could use the summarize() function here instead. By using the summarize() function instead of the $ operator, my code more closely follows the tidyverse guidelines. This esures that my code is readable, clear, and efficient.


```

-   Example 2

```{r}
#| label: dsm-1-2

simulate_means <- function(n, df){
  map_dbl(.x = 1: n, 
          .f = ~rchisq(n = 100, df = df) %>% mean()
          )
}

grid <- crossing(n = c(10,
                       100,
                       1000,
                       10000
                       ), 
                 df = 10)

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, 
                                          df = df
                                          ), 
                                .f = simulate_means)
         ) |> 
  unnest(simulated_means) 

# This code is from lab 9, questions 4-6. 

```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

teacher_evals <- read_csv(here("data", "teacher_evals.csv"))

teacher_evals_compare <- teacher_evals |> 
  filter(question_no == 903) |> 
  mutate(SET_level = if_else(SET_score_avg >= 4,
                             "excellent",
                             "standard"
                             ), 
         sen_level = if_else(seniority <= 4,
                              "junior",
                              "senior"
                              )
          
         ) |>
  select(course_id, 
         SET_level, 
         sen_level
         )

chi_square_test <- chisq.test(teacher_evals_compare$SET_level, 
                              teacher_evals_compare$sen_level
                              )

print(chi_square_test)

# This code is from challenge 3, questions 1 and 3


```

-   Example 2

```{r}
#| label: dsm-2-2

species_mod <- aov(formula = weight ~species_id, 
  data = surveys
                )

summary(species_mod)

# This code is from lab 4, question 8

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

After receiving feedback on each lab, I submitted revisions with reflections for all labs where revisions were accepted, dedicating significant time to understanding my mistakes, correcting them, and enhancing the efficiency of my code. As someone without much coding experience prior to this course, learning how to use R has been a constructively challenging experience. Working through lab assignments has provided me with the opportunity to struggle through material, enhancing my critical thinking and my tangible coding skills. Then, through feedback, I have learned where I was not fully grasping a concept or where I could make my code more efficient. With this feedback, I was able to explore the content more deeply and consider other approaches to coding specific problems. 

For each problem I received a growing on or problems where I received a success but received feedback, when I completed my revision and reflection, I truly sat with the material, considering the importance of the changes I was implementing.  I made sure to consider and explain why it was important to fix or include what I added in my revision. For example, in lab 3, I initially saved unnecessary objects or created new data frames and did not display the results of my code in the quarto document. I did not originally see this as an issue when working on the lab assignment. However, once I received feedback on this aspect of my lab, I became aware of the issue in my lab. I realized I needed to consider when it is necessary and beneficial to save objects and create data frames and when it is unnecessary, a concept I had not considered before. I also realized that my reader was unable to see the results of my code often. I then considered and reflected on the fact that I was not providing the necessary information to the reader of my quarto document for them to be able to understand and follow my lab. Through reflections like these, I gained insight into efficient coding practices and ensuring my coding serves its intended and appropriate purpose.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

Throughout this course so far, I have challenged myself to work through material I did not understand initially. I attempted challenge problems, not always getting them perfectly right. When I received feedback, I made sure to revise these as it was important to me to push myself to deepen my understanding and enhance my coding skills through these more complex problems. I personally also felt challenged by many problems within the lab assignments and spent considerable time thinking out problems and potential ways of coding to solve these problems. 

In my portfolio, I have included code from Challenge 3. This is an example of a problem I attempted and succeeded at, yet found very difficult. In this challenge we were provided with a plot and instructed to write code to recreate this plot. This required me to work backwards and consider all of the components needed to create the plot. I found this problem challenging and worked on it for a while. I struggled with this problem initially, but this struggle was part of the learning experience, ultimately deepening my understanding of making visualizations in R. 

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

*\
*Here is an example of peer feedback I provided to a classmate for their Lab 2:

Question 1 - Correctly loaded the R packages needed for your analysis\
Question 2 - Correctly used the here() package to load in the data\
Question 3 - You used the glimpse() function to provide a brief overview of the dataset which was a great way to display information about your dataset. However, in your description of the data, you said the dataset contains about 8015 students. Although there are 8015 rows, each row does not correlate to an individual student. If you look at the first three columns, this provides information on what each row represents.\
Question 4 - Each row represents one question from the SET questionnaire for each class section for a specific teacher. I would make sure to include this aspect because this is a crucial aspect of what differentiates each row.\
Question 5 - Your code looks really great in this question. One thing you could do to tidy up your code is in your select() line, you could make a new line after each comma.\
Question 6 - Your code looks great and provides the information you need! If you wanted to, you could make this code into one chunk of code!\
Question 7 - Your code provides the instructor and course with missing values.\
Question 8 - I like that you chose to include a barchart to show the demographics of the instructors in the study!\
Question 9 - The code you wrote looks great! You might want to tidy it up a little bit by making a new line after commas\
Question 10 - Your code looks great!\
Question 11 - Your code looks great!\
Question 12 - Your code looks great!

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

In weekly pair programming activities, I felt I was always able to be patient and respectful and ensure my partner's input was valued and considered. I made it a priority to listen as the coder to create a collaborative environment where I valued my partner’s perspective and also learned from their ideas and coding approach. Although I had some difficulties communicating when I felt my voice wasn’t being heard and wish I did to ensure my ideas were being considered, I feel I have become more capable and confident redirecting our focus to maintain our respective roles and enhance our collaboration.
