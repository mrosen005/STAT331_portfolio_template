---
title: "STAT 331 Portfolio"
author: "Miriam Rosen"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A-.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r}
#| label: wd-1-csv

surveys <- read_csv(here("data", "surveys.csv"))

# This code is from lab 2, question 1

```

-   `xlsx`

```{r}
#| label: wd-1-xlsx

agesxl <- read_xlsx(path = here::here("check-ins", "2.1-loading-data", "Ages_Data", "ages.xlsx"), sheet = "ages")

# This code is from Check-in 2.3

```

-   `txt`

```{r}
#| label: wd-1-txt

ages_tab <- read_table(file = here::here("Week 2", "Check-ins", "Ages_Data", "ages_tab.txt"))


# This code is from Check-in 2.3


```

**WD-2: I can select necessary columns from a dataset.**

```{r}
#| label: wd-2

teacher_evals_clean <- teacher_evals |> 
  rename(sex = gender) |> 
  filter(no_participants > 10) |> 
  mutate(teacher_id  = as.character(teacher_id)) |>
  select(course_id, 
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
        )

# This code is from lab 3, question 5


```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r}
#| label: wd-3-numeric

teacher_evals_clean <- teacher_evals |> 
  rename(sex = gender) |> 
  filter(no_participants > 10) |> 
  mutate(teacher_id  = as.character(teacher_id)) |>
  select(course_id, 
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
        )

# This code is from lab 3, question 5


```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-3-string

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

# This code is from lab 4, question 2 

```

-   factor

```{r}
#| label: wd-3-factor

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

# This code is from lab 4, question 2

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date

crime_scene_report |> 
  mutate(date = ymd(date)) |> 
  filter(date == ymd("2018-01-15"), 
         type == "murder",
         city == "SQL City"
         ) 

# This code is from lab 5, section 1: Crime Scene Report

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

```{r}
#| label: wd-4-numeric

teacher_evals |> 
  filter(question_no == 903) |> 
  mutate(SET_level = if_else(SET_score_avg >= 4,
                             "excellent",
                             "standard"
                             ), 
         sen_level = if_else(seniority <= 4,
                              "junior",
                              "senior"
                              )
          
         ) |>
  select(course_id, 
         SET_level, 
         sen_level
         )

# This code is from challenge 3, question 1

```

-   character -- specifically a string (example must use functions from **stringr**)

```{r}
#| label: wd-4-string

person |> 
  mutate(is_annabel = str_detect(name, "^Annabel")) |>
  filter(address_street_name == "Franklin Ave",
         is_annabel
          )
      
# This code is from lab 5, section 3: Finding Witness 2. I changed the way I identified rows with names that start with Annabel by using the mutate() function to create a new column which detects strings beginning with Annabel. Then, I filtered for rows that contained a string beginning with Annabel and rows of individuals who live on Franklin Ave. 

```

-   factor (example must use functions from **forcats**)

```{r}
#| label: wd-4-factor

ca_childcare <- ca_childcare |> 
 mutate(county_name = str_remove(county_name, " County")) |>
  mutate(region = fct_collapse(county_name,
                               "Superior California" = c("Butte",
                                                         "Colusa",
                                                         "El Dorado",
                                                         "Glenn", 
                                                         "Lassen", 
                                                         "Modoc",
                                                         "Nevada",
                                                         "Placer", 
                                                         "Plumas", 
                                                         "Sacramento", 
                                                         "Shasta", 
                                                         "Sierra", 
                                                         "Siskiyou",
                                                         "Sutter", 
                                                         "Tehama", 
                                                         "Yolo",
                                                         "Yuba"
                                                         ),
                               "North Coast" = c("Del Norte",
                                                 "Humboldt",
                                                 "Lake",
                                                 "Mendocino", 
                                                 "Napa", "Sonoma", 
                                                 "Trinity"
                                                 ),
                               "San Francisco Bay Area" = c("Alameda", 
                                                            "Contra Costa", 
                                                            "Marin", 
                                                            "San Francisco", 
                                                            "San Mateo", 
                                                            "Santa Clara",
                                                            "Solano"
                                                            ),
                               "Northern San Joaquin Valley" = c("Alpine", 
                                                                 "Amador", 
                                                                 "Calaveras",
                                                                 "Madera",
                                                                 "Mariposa",
                                                                 "Merced", 
                                                                 "Mono", 
                                                                 "San Joaquin", "Stanislaus", 
                                                                 "Tuolumne"
                                                                ),
                               "Central Coast" = c("Monterey",
                                                   "San Benito",
                                                   "San Luis Obispo",
                                                   "Santa Barbara",
                                                   "Santa Cruz",
                                                   "Ventura"
                                                   ),
                               "Southern San Joaquin Valley" = c("Fresno",
                                                                 "Inyo",
                                                                 "Kern",
                                                                 "Kings",
                                                                 "Tulare"
                                                                 ),
                               "Inland Empire" = c("Riverside",
                                                   "San Bernardino"
                                                         ),
                               "Los Angeles County" = c("Los Angeles"),
                               "Orange County" = c("Orange"),
                               "San Diego - Imperial" = c("San Diego",
                                                    "Imperial"
                                                    )
                               )
         ) 

# This code is from lab 4, question 3

```

-   date (example must use functions from **lubridate**)

```{r}
#| label: wd-4-date

crime_scene_report |> 
  mutate(date = ymd(date)) |> 
  filter(date == ymd("2018-01-15"), 
         type == "murder",
         city == "SQL City"
         )

# This code is from lab 5, section 1: Crime Scene Report 

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r}
#| label: wd-5-left

get_fit_now_member |> 
  filter(membership_status == "gold",
         str_detect(id,
                   "48Z"
                   )
         ) |>
  left_join(get_fit_now_check_in,
             by = c("id" = "membership_id"
                     )
              ) |>
  mutate(check_in_date = ymd(check_in_date)) |>
  filter(check_in_date == ymd("2018-01-09")) |>  
  left_join(person, 
            by = c("person_id" = "id"
                   ) 
         ) |> 
  left_join(drivers_license,
            by = c("license_id" = "id"
                   )
            ) |>
  filter(str_detect(plate_number,
                      "H42W"
                  )
          )

# This code is from lab 5, section 5: Using Witness's Clues. Although I realize this code would be more effective using the inner_join() function, the left_join still works. I do not have other examples from my lab assignments of left_join so am keeping this in here temporarily. 



```

-   `right_join()`

```{r}
#| label: wd-5-right

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

# This code is from lab 4, question 2

```

-   `inner_join()`

```{r}
#| label: wd-5-inner

get_fit_now_member |> 
  filter(membership_status == "gold",
         str_detect(id,
                   "48Z"
                   )
         ) |>
  inner_join(get_fit_now_check_in,
             by = c("id" = "membership_id"
                     )
              ) |>
  mutate(check_in_date = ymd(check_in_date)) |>
  filter(check_in_date == ymd("2018-01-09")) |>  
  inner_join(person, 
            by = c("person_id" = "id"
                   ) 
         ) |> 
  inner_join(drivers_license,
            by = c("license_id" = "id"
                   )
            ) |>
  filter(str_detect(plate_number,
                      "H42W"
                  )
          )


# This code is from lab 5, section 5: Using Witness's Clues. I originally used left_join(), which works, but creates NA's when the second dataset does not have a matching row with nformation. It is more effective for this question to use the inner_join() function so that we only get rows that are in both data sets since I am trying to narrow down these datasets to one row based on the factors included in this code. 

```

-   `full_join()`

```{r}
#| label: wd-5-full

# Have not done yet! 

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi

witnesses <- bind_rows(person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            ), 
  person |> 
  filter(address_street_name == "Franklin Ave",
         (str_detect(name, "Annabel"
                     )
          )
         )
  )

# This code is from lab 5, section 4: Examining Witness Interviews. Originally, I hard coded the person_id number. To make my code more flexible, I saved the narrowed-down witness results in a data frame. Then, I used the semi_join() function to combine this data frame with the interview data to access the witness's statements. 


```

-   `anti_join()`

```{r}
#| label: wd-6-anti


degrees_not <- tibble(academic_degree = c("no_dgr", "ma"))

teacher_evals_clean |> 
  anti_join(degrees_not,
            by = "academic_degree"
            ) |>
  filter(sex == "female") |>
  group_by(teacher_id) |>
  summarise(average_response = mean(resp_share,
                                    na.rm = TRUE
                                    ),
            .groups = 'drop'
            ) |>
  mutate(max_values = max(average_response),
         min_values = min(average_response)
         ) |> 
    filter(average_response == max_values | average_response == min_values) |> 
    arrange(average_response) |>
    select(teacher_id, 
           average_response
           ) |>
  print()

# This code is from lab 3, question 12. I originally used the filter() function in my original code to filter to include specific academic degrees. To utilize the anti_join() function, I created a tibble which included the two academic degrees that I did not want to have in my average responses. Then, I used the anti_join to join the teacher_evals_clean data set with the degrees_not data set to filter to only include academic degrees that do not have matches in the degrees_not data set. 


```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  pivot_longer(cols = starts_with("mc_"), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
 mutate(fct_relevel = age, "mc_infant",
                          "mc_toddler",
                          "mc_preschool") |> 
  drop_na()


# This code is from lab 4, question 6

```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide

mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income) |> 
  arrange(desc(`2008`), 
          desc(`2018`
              )
          ) |> 
  rename(`Median Household Income in 2008` = `2008`,
         `Median Household Income in 2018` = `2018`
         ) |>
  print()

# This code is from lab 4, question 4. I added column names that were more descriptive so that the reader knows what these columns represent. This is important so that the data frame can be understood by readers.

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

Using my YAML to incorporate various aspects to my rendered document such as code-folding and embedding resources, I am able to make my rendered quarto documents look professional. Addd

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
#| label: r-2-1

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level,
                     fill = SET_level)
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("steelblue",
                               "orange3"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       )

# This code is from challenge 3, question 2

```

-   Example of **dplyr** pipeline

```{r}
#| label: r-2-2

mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income) |> 
  arrange(desc(`2008`), 
          desc(`2018`
              )
          ) |> 
  rename(`Median Household Income in 2008` = `2008`,
         `Median Household Income in 2018` = `2018`
         ) |>
  print()

# This code is from lab 4, question 4. I added column names that were more descriptive so that the reader knows what these columns represent. This is important so that the data frame can be understood by readers.

```

-   Example of function formatting

```{r}
#| label: r-2-3

# Do not have yet! 

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

```{r}
#| label: r-3-example

person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            )

# This code is from lab 5, section 4: Examining Witness Interviews. I removed the arrange() function that I had originally included before slice_max() because the slice_max() function  finds the maximum value based on the specified information, making it unecessary to arrange() the data beforehand.

```

-   Example of function stops

```{r}
#| label: r-3-function-stops

# Do not have yet!  

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

```{r}
#| label: dvs-1-num

ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot
Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

# This code is from lab 2, question 4

```

-   at least one numeric variable and one categorical variable

```{r}
#| label: dvs-2-num-cat


ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot
Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

# This code is from lab 2, question 4


```

-   at least two categorical variables

```{r}
#| label: dvs-2-cat


ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level, fill = SET_level)
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("steelblue",
                               "orange3"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       )

# This code is from challenge 3, question 2

```

-   dates (timeseries plot)

```{r}
#| label: dvs-2-date

# Do not have yet!  

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

```{r}
#| label: dvs-2-1


ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot
Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

# This code is from lab 2, question 4

```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-2

ggplot(data = surveys, 
       mapping = aes(x = species, 
          y = weight
                    )
       ) + 
geom_boxplot(outliers = FALSE) +
geom_jitter(
   color = "orange", 
          alpha = 0.1
            ) +
  theme(axis.text.x = element_text(angle = 45)
        ) +
labs(x = "Species", 
     y = "Weight (in grams)", 
     title = "Weight Distributions Across Rodent Species")

# This code is from lab 2, question 8

```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-3

# Do not have yet! 

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

```{r}
#| label: dvs-3-1

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level, fill = SET_level)
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("steelblue",
                               "orange3"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       )

# This code is from challenge 3, question 2

```

-   I can use annotations

```{r}
#| label: dvs-3-2



```

-   I can be creative...

```{r}
#| label: dvs-3-3



```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
#| label: dvs-4-summarize

teacher_evals_clean |> 
  summarize(courses = n_distinct(course_id), 
            instructors = n_distinct(teacher_id)
            )

# This code is from lab 3, question 6 

```

-   Example using `across()`

```{r}
#| label: dvs-4-across

# Do not have yet! 

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1

teacher_evals_clean |>
   distinct(teacher_id, academic_degree) |>
   group_by(academic_degree) |>
  summarize(count = n())

# This code is from lab 3, question 8


```

-   Example 2

```{r}
#| label: dvs-5-2

teacher_evals_clean |>
   distinct(teacher_id, seniority) |>
   group_by(seniority) |>
  summarize(count = n())

# This code is from lab 3, question 8



```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

```{r}
#| label: dvs-6-1

teacher_evals_clean |>
   distinct(teacher_id, seniority) |>
   group_by(seniority) |>
   summarize(count = n())

# This code is from lab 3, question 8


```

-   Example 2

```{r}
#| label: dvs-6-2

teacher_evals_clean |>
   distinct(teacher_id, academic_degree) |>
   group_by(academic_degree) |>
   summarize(count = n())

# This code is from lab 3, question 8

```

**DVS-7: I show creativity in my tables.**

-   Example 1

```{r}
#| label: dvs-7-1

# Do not have yet!

```

-   Example 2

```{r}
#| label: dvs-7-2

# Do not have yet!

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
#| label: pe-1-one-call

crime_scene_report |> 
  mutate(date = ymd(date)) |> 
  filter(date == ymd("2018-01-15"), 
         type == "murder",
         city == "SQL City"
         )

# This code is from lab 5, section 1: Crime Scene Report


```

-   `across()`

```{r}
#| label: pe-1-across

# Do not have yet! 

```

-   `map()` functions

```{r}
#| label: pe-1-map-1

# Do not have yet!

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

```{r}
#| label: pe-2-1

# Do not have yet! 


```

-   Function that operates on data frames

```{r}
#| label: pe-2-2

# Do not have yet! 


```

**PE-3:I can use iteration to reduce repetition in my code.**

-   `across()`

```{r}
#| label: pe-3-across


# Do not have yet! 


```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1

# Do not have yet! 

```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

```{r}
#| label: pe-3-map-2

# Do not  have yet! 

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
#| label: pe-4-1

mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income) |> 
  arrange(desc(`2008`), 
          desc(`2018`
              )
          ) |> 
  rename(`Median Household Income in 2008` = `2008`,
         `Median Household Income in 2018` = `2018`
         ) |>
  print()

# This code is from lab 4, question 4. I added column names that were more descriptive so that the reader knows what these columns represent. This is important so that the data frame can be understood by readers.

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
#| label: pe-4-2

ca_childcare2 <- ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  pivot_longer(cols = starts_with("mc_"), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
 mutate(fct_relevel = age, "mc_infant",
                          "mc_toddler",
                          "mc_preschool") |> 
  drop_na()

ggplot(data = ca_childcare2, 
       mapping = aes(x = study_year,
                          y = median_income,
                          color = region
                          )
       ) +
  geom_point() + 
  geom_smooth() + 
  facet_wrap(~ age,
             scales = "free_y"
             ) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 1
                                  )
                     ) +
    theme(axis.text.x = element_text(angle = 45)
          ) 

# This code is from lab 3, question 6


```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1 

# Do not have yet! 

```

-   Example 2

```{r}
#| label: dsm-1-2

# Do not have yet! 

```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
#| label: dsm-2-1

teacher_evals <- read_csv(here("data", "teacher_evals.csv"))

teacher_evals_compare <- teacher_evals |> 
  filter(question_no == 903) |> 
  mutate(SET_level = if_else(SET_score_avg >= 4,
                             "excellent",
                             "standard"
                             ), 
         sen_level = if_else(seniority <= 4,
                              "junior",
                              "senior"
                              )
          
         ) |>
  select(course_id, 
         SET_level, 
         sen_level
         )

chi_square_test <- chisq.test(teacher_evals_compare$SET_level, 
                              teacher_evals_compare$sen_level
                              )

print(chi_square_test)

# This code is from challenge 3, questions 1 and 3


```

-   Example 2

```{r}
#| label: dsm-2-2

species_mod <- aov(formula = weight ~species_id, 
  data = surveys
                )

summary(species_mod)

# This code is from lab 4, question 8

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

After receiving feedback on each lab, I have submitted revisions with reflections, dedicating significant time to understanding my mistakes, correcting them, and enhancing the efficiency of my code. As someone without much coding experience prior to this course, learning how to use R has been a constructively challenging experience. Working through lab assignments has provided me with the opportunity to struggle through material, enhancing my critical thinking as well as my tangible coding skills. Then, through feedback, I have learned where I was not fully grasping a concept or where I could make my code more efficient. With this feedback, I was able to explore the content more deeply and consider other approaches to coding specific problems. 

For each problem I received a growing on or problems where I received a success but received feedback, when I completed my revision and reflection, I truly sat with the material, considering the importance of the changes I was implementing.  I made sure to consider and explain why it was important to fix or include what I added in my revision. For example, in lab 3, I initially saved unnecessary objects or created new data frames and did not display the results of my code in the quarto document. I did not originally see this as an issue when working on the lab assignment. However, once I received feedback on this aspect of my lab, I became aware of the issue in my lab. I realized I needed to consider when it is necessary and beneficial to save objects and create data frames and when it is unnecessary, a concept I had not considered before. I also realized that my reader was unable to see the results of my code often. I then considered and reflected on the fact that I was not providing the necessary information to the reader of my quarto document for them to be able to understand and follow my lab. Through reflections like these, I gained insight into efficient coding practices and ensuring my coding serves its intended and appropriate purpose.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

Throughout this course so far, I have challenged myself to work through material I did not understand initially. I attempted challenge problems, not always getting them perfectly right. When I received feedback, I made sure to revise these as it was important to me to push myself to deepen my understanding and enhance my coding skills through these more complex problems. I personally also felt challenged by many problems within the lab assignments and spent considerable time thinking out problems and potential ways of coding to solve these problems. 

In my portfolio, I have included code from Challenge 3. This is an example of a problem I attempted and succeeded at, yet found very difficult. In this challenge we were provided with a plot and instructed to write code to recreate this plot. This required me to work backwards and consider all of the components needed to create the plot. I found this problem challenging and worked on it for a while. I struggled with this problem initially, but this struggle was part of the learning experience, ultimately deepening my understanding of making visualizations in R. 

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

*\
*Here is an example of peer feedback I provided to a classmate for their Lab 2:

Question 1 - Correctly loaded the R packages needed for your analysis \
Question 2 - Correctly used the here() package to load in the data \
Question 3 - You used the glimpse() function to provide a brief overview of the dataset which was a great way to display information about your dataset. However, in your description of the data, you said the dataset contains about 8015 students. Although there are 8015 rows, each row does not correlate to an individual student. If you look at the first three columns, this provides information on what each row represents. \
Question 4 - Each row represents one question from the SET questionnaire for each class section for a specific teacher. I would make sure to include this aspect because this is a crucial aspect of what differentiates each row. \
Question 5 - Your code looks really great in this question. One thing you could do to tidy up your code is in your select() line, you could make a new line after each comma. \
Question 6 - Your code looks great and provides the information you need! If you wanted to, you could make this code into one chunk of code! \
Question 7 - Your code provides the instructor and course with missing values.\
Question 8 - I like that you chose to include a barchart to show the demographics of the instructors in the study!\
Question 9 - The code you wrote looks great! You might want to tidy it up a little bit by making a new line after commas\
Question 10 - Your code looks great! \
Question 11 - Your code looks great! \
Question 12 - Your code looks great!

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

In weekly pair programming activities, I felt I was always able to be patient and respectful and ensure my partner's input was valued and considered. I made it a priority to listen as the coder to create a collaborative environment where I valued my partner’s perspective and also learned from their ideas and coding approach. Although I had some difficulties communicating when I felt my voice wasn’t being heard and wish I did to ensure my ideas were being considered, I feel I have become more capable and confident redirecting our focus to maintain our respective roles and enhance our collaboration.
