---
title: "STAT 331 Portfolio"
author: "Miriam Rosen"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2)

*Note: For changes to labs 8 and 9, where revisions were not accepted, revisions made for my portfolio are denoted by italics.*

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

This code is from lab 2, question 1.

```{r}
#| label: wd-1-csv

surveys <- read_csv(here("data",
                         "surveys.csv"
                         )
                    )

```

-   `xlsx`

This code is from Check-in 2.3.

```{r}
#| label: wd-1-xlsx

agesxl <- read_xlsx(path = here::here("check-ins",
                                      "2.1-loading-data",
                                      "Ages_Data",
                                      "ages.xlsx"
                                      ), 
                    sheet = "ages"
                    )


```

-   `txt`

This code is from Check-in 2.3.

```{r}
#| label: wd-1-txt

ages_tab <- read_table(file = here::here("Week 2",
                                         "Check-ins",
                                         "Ages_Data",
                                         "ages_tab.txt"
                                         )
                       )

```

**WD-2: I can select necessary columns from a dataset.**

This code is from lab 3, question 5.

```{r}
#| label: wd-2

teacher_evals_clean <- teacher_evals |> 
  rename(sex = gender) |> 
  filter(no_participants > 10) |> 
  mutate(teacher_id  = as.character(teacher_id)) |>
  select(course_id, 
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
        )

```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

This code is from lab 3, question 5.

```{r}
#| label: wd-3-numeric

teacher_evals_clean <- teacher_evals |> 
  rename(sex = gender) |> 
  filter(no_participants > 10) |> 
  mutate(teacher_id  = as.character(teacher_id)) |>
  select(course_id, 
         teacher_id, 
         question_no, 
         no_participants, 
         resp_share, 
         SET_score_avg, 
         percent_failed_cur, 
         academic_degree, 
         seniority, 
         sex
        )

```

-   character -- specifically a string (example must use functions from **stringr**)

This code is from lab 5, section 2: Finding Witnesses.

```{r}
#| label: wd-3-string

witnesses <- bind_rows(person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            ), 
  person |> 
  mutate(is_annabel = str_detect(name,
                                 "^Annabel"
                                 )
         ) |>
  filter(address_street_name == "Franklin Ave",
         is_annabel
          )
  )

```

-   factor

This code is from lab 4, question 2.

```{r}
#| label: wd-3-factor

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

```

-   date (example must use functions from **lubridate**)

This code is from lab 5, section 6: Finding Person Responsible.

```{r}
#| label: wd-3-date

suspect <- person |>
  inner_join(drivers_license,
             join_by(license_id == id)) |>
  inner_join(facebook_event_checkin,
             join_by(id == person_id)) |>
  mutate(concert_month = month(ymd(date))) |>
  filter(gender == "female",
         height %in% c("65","66",
                        "67"
                        ),
         hair_color == "red",
         car_model == "Model S",
         car_make == "Tesla", 
         event_name == "SQL Symphony Concert",
         concert_month == 12,
         year(ymd(date)) == 2017
         ) |> 
  group_by(id, name) |> 
  summarize(event_name = n(), 
            .groups = "drop"
            ) |> 
  filter(event_name == 3) |>
  print()

```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric (using `as.numeric()` is not sufficient)

This code is from challenge 3, question 1.

```{r}
#| label: wd-4-numeric

teacher_evals |> 
  filter(question_no == 903) |> 
  mutate(SET_level = if_else(SET_score_avg >= 4,
                             "excellent",
                             "standard"
                             ), 
         sen_level = if_else(seniority <= 4,
                              "junior",
                              "senior"
                              )
          
         ) |>
  select(course_id, 
         SET_level, 
         sen_level
         )

```

-   character -- specifically a string (example must use functions from **stringr**)

This code is from lab 5, section 2: Finding Witnesses.

```{r}
#| label: wd-4-string

witnesses <- bind_rows(person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            ), 
  person |> 
  mutate(is_annabel = str_detect(name,
                                 "^Annabel"
                                 )
         ) |>
  filter(address_street_name == "Franklin Ave",
         is_annabel
          )
  )

```

-   factor (example must use functions from **forcats**)

This code is from lab 4, question 3.

```{r}
#| label: wd-4-factor

ca_childcare <- ca_childcare |> 
 mutate(county_name = str_remove(county_name,
                                 " County"
                                 )
        ) |>
  mutate(region = fct_collapse(county_name,
                               "Superior California" = c("Butte",
                                                         "Colusa",
                                                         "El Dorado",
                                                         "Glenn", 
                                                         "Lassen", 
                                                         "Modoc",
                                                         "Nevada",
                                                         "Placer", 
                                                         "Plumas", 
                                                         "Sacramento", 
                                                         "Shasta", 
                                                         "Sierra", 
                                                         "Siskiyou",
                                                         "Sutter", 
                                                         "Tehama", 
                                                         "Yolo",
                                                         "Yuba"
                                                         ),
                               "North Coast" = c("Del Norte",
                                                 "Humboldt",
                                                 "Lake",
                                                 "Mendocino", 
                                                 "Napa", "Sonoma", 
                                                 "Trinity"
                                                 ),
                               "San Francisco Bay Area" = c("Alameda", 
                                                            "Contra Costa", 
                                                            "Marin", 
                                                            "San Francisco", 
                                                            "San Mateo", 
                                                            "Santa Clara",
                                                            "Solano"
                                                            ),
                               "Northern San Joaquin Valley" = c("Alpine", 
                                                                 "Amador", 
                                                                 "Calaveras",
                                                                 "Madera",
                                                                 "Mariposa",
                                                                 "Merced", 
                                                                 "Mono", 
                                                                 "San Joaquin", "Stanislaus", 
                                                                 "Tuolumne"
                                                                ),
                               "Central Coast" = c("Monterey",
                                                   "San Benito",
                                                   "San Luis Obispo",
                                                   "Santa Barbara",
                                                   "Santa Cruz",
                                                   "Ventura"
                                                   ),
                               "Southern San Joaquin Valley" = c("Fresno",
                                                                 "Inyo",
                                                                 "Kern",
                                                                 "Kings",
                                                                 "Tulare"
                                                                 ),
                               "Inland Empire" = c("Riverside",
                                                   "San Bernardino"
                                                         ),
                               "Los Angeles County" = c("Los Angeles"),
                               "Orange County" = c("Orange"),
                               "San Diego - Imperial" = c("San Diego",
                                                    "Imperial"
                                                    )
                               )
         ) 

```

-   date (example must use functions from **lubridate**)

This code is from lab 5, section 6: Finding Person Responsible.

```{r}
#| label: wd-4-date

suspect <- person |>
  inner_join(drivers_license,
             join_by(license_id == id)) |>
  inner_join(facebook_event_checkin,
             join_by(id == person_id)) |>
  mutate(concert_month = month(ymd(date))) |>
  filter(gender == "female",
         height %in% c("65","66",
                        "67"
                        ),
         hair_color == "red",
         car_model == "Model S",
         car_make == "Tesla", 
         event_name == "SQL Symphony Concert",
         concert_month == 12,
         year(ymd(date)) == 2017
         ) |> 
  group_by(id, name) |> 
  summarize(event_name = n(), 
            .groups = "drop"
            ) |> 
  filter(event_name == 3) |>
  print()

```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

This code is from lab 5, section 4: Using Witness's Clues. Although using the inner_join() function would be more efficient, using the left_join() function still achieves the same result. The inner_join() function is more effective because it retain rows where there is a match between the keys in both data sets. When using the left_join() function, all of the rows from the left dataset are kept, meaning that if there are unmatched rows in the right data set, there will be rows with NA cells. This leads the resulting joined dataset to potentially have irrelevant observations and be less clean than if the inner_join() function was used.

```{r}
#| label: wd-5-left

get_fit_now_member |> 
  filter(membership_status == "gold",
         str_detect(id,
                   "48Z"
                   )
         ) |>
  left_join(get_fit_now_check_in,
             by = c("id" = "membership_id"
                     )
              ) |>
  mutate(check_in_date = ymd(check_in_date)) |>
  filter(check_in_date == ymd("2018-01-09")) |>  
  left_join(person, 
            by = c("person_id" = "id"
                   ) 
         ) |> 
  left_join(drivers_license,
            by = c("license_id" = "id"
                   )
            ) |>
  filter(str_detect(plate_number,
                      "H42W"
                  )
          )

```

-   `right_join()`

This code is from lab 4, question 2.

```{r}
#| label: wd-5-right

ca_childcare <- counties |> 
  filter(state_abbreviation == "CA") |>
  right_join(childcare_costs,
             by = "county_fips_code"
             )

```

-   `inner_join()`

This code is from lab 5, section 4: Using Witness's Clues. I originally used left_join(), which works to combine the data sets, but includes NA's when the second data set does not have a matching row. For this task, using the inner_join() function is more effective because it only retains rows with matching data, aligning better with the goal of this task to narrow down the data sets to a single row based on the specified factors in the code.

```{r}
#| label: wd-5-inner

get_fit_now_member |> 
  filter(membership_status == "gold",
         str_detect(id,
                   "48Z"
                   )
         ) |>
  inner_join(get_fit_now_check_in,
             by = c("id" = "membership_id"
                     )
              ) |>
  mutate(check_in_date = ymd(check_in_date)) |>
  filter(check_in_date == ymd("2018-01-09")) |>  
  inner_join(person, 
            by = c("person_id" = "id"
                   ) 
         ) |> 
  inner_join(drivers_license,
            by = c("license_id" = "id"
                   )
            ) |>
  filter(str_detect(plate_number,
                      "H42W"
                  )
          )

```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

This code is from lab 5, section 3: Examining Witness Interviews.

```{r}
#| label: wd-6-semi

interview |> 
    semi_join(witnesses, 
            by = c("person_id" = "id")
            )

```

-   `anti_join()`

This code is from lab 3, question 12. I originally used the filter() function in my original code to filter to include specific academic degrees. To utilize the anti_join() function, I created a tibble which included the two academic degrees that I did not want to have in my average responses. Then, I used the anti_join to join the teacher_evals_clean data set with the degrees_not data set to filter to only include academic degrees that do not have matches in the degrees_not data set.

```{r}
#| label: wd-6-anti


degrees_not <- tibble(academic_degree = c("no_dgr",
                                          "ma"
                                          )
                      )

teacher_evals_clean |> 
  anti_join(degrees_not,
            by = "academic_degree"
            ) |>
  filter(sex == "female") |>
  group_by(teacher_id) |>
  summarise(average_response = mean(resp_share,
                                    na.rm = TRUE
                                    ),
            .groups = 'drop'
            ) |>
  mutate(max_values = max(average_response),
         min_values = min(average_response)
         ) |> 
    filter(average_response == max_values | average_response == min_values) |> 
    arrange(average_response) |>
    select(teacher_id, 
           average_response
           ) |>
  print()

```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

This code is from lab 4, question 6.

```{r}
#| label: wd-7-long

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8,
                                     "Accent"
                                     )
                          )(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

```

-   `pivot_wider()`

This code is from lab 4, question 4.

```{r}
#| label: wd-7-wide


mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income,
              names_prefix = "Median Household Income in ") |> 
  arrange(desc(`Median Household Income in 2008`), 
          desc(`Median Household Income in 2018`)
          ) |>
  rename("Region" = region) |>
  print()

```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I have done this in the following provided assignments:

I have demonstrated this learning target in my lab assignments throughout this quarter. Firstly, in the YAML of my quarto documents, I have incorporated various features to my rendered document such as code-folding and embedding resources, enhancing the professionalism of my rendered quarto documents. One lab I am particularly proud of for its professional appearance is lab 5. In this lab, I formatted my own quarto document and included section headers to make clear sections for the viewer to be able to easily follow. Secondly, I have made a conscious effort to write tidy code, adhering to the tidyverse style guidelines, using named arguments, and starting new lines after commas, plus signs, and pipe operators. Additionally, I have been thoughtful to ensure that my code is efficient, specifically using one function to perform multiple operations and calculating multiple summary statistics by using functions such as the summarize and across functions. Lastly, I have learned how to use and implement the here function into my projects to load in data of various formats including csv, xlsx, and txt files.

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

This code is from challenge 3, question 2. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors.

```{r}
#| label: r-2-1

# Initializing a plot using the dataset, teacher_evals_compare, with seniority level mapped to the x axis and SET level mapped to fill color. 
ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level,
                     fill = SET_level
                     )
       ) +
# Creating a stacked barplot to count observations
  geom_bar(stat = "count",
           position = "stack"
           ) + 
# Adding colors to the SET levels, excellent and standard
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                  ) +
# Adding a background theme
  theme_bw() +
# Adding labels to x axis, adding a title, and removing a label from the y axis to prevent viewers from having to tilt their heads 
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections"
       ) +
# Adding annotations on the bars to display the count of each SET_level category
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
# Removes legend from visualization
  theme(legend.position = "none") 

```

-   Example of **dplyr** pipeline

This code is from lab 4, question 4.

```{r}
#| label: r-2-2


# Selecting columns from the ca_childcare dataset  
mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
# Filtering the dataset to only include the years, 2008 and 2018
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
# Grouping the data by region and study_year 
  group_by(region,
           study_year
           ) |>
# Calculating the median household income for each region in 2008 and 2018  
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
# Pivoting the data to a wider format, where each study year, 2008 and 2018, have their own column with the values in these two columns being the median household incomes for respective regions
  pivot_wider(names_from = study_year,
              values_from = median_household_income,
              # Adding a prefix to new columns for clarity 
              names_prefix = "Median Household Income in "
              ) |>  
# Arranging the rows in descending order of median household income for 2008 and 2018
  arrange(desc(`Median Household Income in 2008`), 
          desc(`Median Household Income in 2018`)
          ) |>
# Renaming the region column to be capitalized for consistency in column names 
  rename("Region" = region) |>
# Printing the final table 
  print()

```

-   Example of function formatting

This code is from lab 7, question 4.

```{r}
#| label: r-2-3

rescale_01 <- function(x) {
  # Checking if the input is a numeric vector and if the input is not numeric, stopping the function and returning an error message. 
  if (!is.numeric(x)) stop("Input vector must be numeric.")
  
  # Checking if the input vector has more than one element and if the input vector does not have more than one element, stopping the function and returning an error message. 
  if (length(x) <= 1) stop("Input vector requires more than one element.")
  
  # Calculating the range of the input vector 
  range_1 <- range(x,
        na.rm = TRUE
        )
  # Subtracting the minimumum value from the input vector and dividing by the difference between the maximum and minimum vale of the input vector to rescale the input vector to a 0-1 range
  (x - range_1[1]) / (range_1[2] - range_1[1])
}

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example -- any context

This code is from lab 5, section 3: Examining Witness Interviews.

```{r}
#| label: r-3-example

person |> 
  filter(address_street_name == "Northwestern Dr") |> 
  slice_max(order_by = address_number,
            n = 1
            )

```

-   Example of function stops

This code is from lab 7, question 4.

```{r}
#| label: r-3-function-stops

rescale_01 <- function(x) {
  if(!is.numeric(x)) stop("Input vector must be numeric.")
  if(length(x) <= 1) stop("Input vector requires more than one element.")
  range_1 <- range(x,
        na.rm = TRUE
        )
  (x - range_1[1]) / (range_1[2] - range_1[1])
}

```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   at least two numeric variables

This code is from lab 2, question 4.

```{r}
#| label: dvs-1-num

ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

```

-   at least one numeric variable and one categorical variable

This code is from lab 2, question 4.

```{r}
#| label: dvs-2-num-cat


ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot Length Across Different Rodent Species", 
      subtitle = "Length of Hindfoot (in mm)"
       )

```

-   at least two categorical variables

This code is from challenge 3, question 2. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors.

```{r}
#| label: dvs-2-cat

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level,
                     fill = SET_level
                     )
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 

```

-   dates (timeseries plot)

This code is from lab 4, question 6.

```{r}
#| label: dvs-2-date

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8,
                                     "Accent"
                                     )
                          )(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can ensure people don't tilt their head

This code is from lab 2, question 4.

```{r}
#| label: dvs-2-1


ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = hindfoot_length
                    )
       ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species) +
  labs(x = "Weight of Rodent (in grams)",
       y = "",
       title = "Relationship Between Body Weight and Hindfoot Length Across Different Rodent Species", 
       subtitle = "Length of Hindfoot (in mm)"
       )

```

-   I can modify the text in my plot to be more readable

The first code chunk is from lab 4, question 6. The second code chunk is from lab 4, question 7.

```{r}
#| label: dvs-2-2

# Code 1
library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8,
                                     "Accent"
                                     )
                          )(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

# Code 2 

ggplot(data = ca_childcare, 
       mapping = aes(x = mhi_2018, 
                     y = mc_infant
                     )
       ) + 
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm",
              color = "steelblue"
              ) +
  labs(title = "Relationship Between Median Household Income and Median Weekly 
  Center-Based Chilcare Cost for an Infant in California",
       x = "Median Household Income (in U.S. dollars)", 
       y = ""
       ) +
  scale_x_continuous(labels = label_dollar()) +
  scale_y_continuous(labels = label_dollar())

```

-   I can reorder my legend to align with the colors in my plot

This code is from lab 4, question 6.

```{r}
#| label: dvs-2-3

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8,
                                     "Accent"
                                     )
                          )(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors

The first code chunk is from challenge 2, spicy. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors. The second code chunk is from lab 9, question 8. I also used <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3> to get my colors for this visualization. *I originally labelled each facet as "Sample Size of \_" instead of " \_ Simulated Means." I realize now that the plot is showing the distributions of simulated means from each of the simulations, not the distribution of means based on sample size. It is important that I accurately label my facets to avoid misleading viewers, ensuring the data and information is interpreted correctly.*

```{r}
#| label: dvs-3-1

# Code 1

library(ggridges)

ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = species, 
        stat = "density_ridges",
        position = "points_sina",
        fill = species
                    )
       ) +
  geom_density_ridges() + 
  labs(x = "Weight (in grams)" , 
     y = "", 
     subtitle = "Species of Rodents",
     title = "Density Ridge Plots of Weights of Various Rodent Species") +
 scale_fill_manual(values = c("torridus" = "#c51b8a", 
                              "spectabilis" = "#fa9fb5", 
                              "penicillatus" = "#f03b20", 
                              "ordii" = "#feb24c", 
                              "merriami" = "#fff7bc", 
                              "megalotis" = "#edf8b1",
                              "maniculatus" =  "#a1d99b",
                              "leucogaster" = "#e5f5f9", 
                              "hispidus" = "#7fcdbb", 
                              "fulvescens" = "#2b8cbe", 
                              "flavus" = "#e7e1ef", 
                              "eremicus" = "#bcbddc", 
                              "baileyi" = "#756bb1", 
                              "albigula" = "#8856a7"
                              )
                   ) +
    theme(legend.position = "none")

# Code 2 

ggplot(data = all_simulations,
         mapping = aes(x = simulated_means)
         ) + 
geom_histogram(color = "#756bb1",
                 fill = "#bcbddc"
                 ) + 
facet_wrap(~ n, 
             scales = "free_y", 
           labeller = labeller(n = c("10" = "10 Simulated Means", 
                                     "100" = "100 Simulated Means", 
                                     "1000" = "1,000 Simulated Means",
                                     "10000" = "10,000 Simulated Means"
                                     )
                               )
             ) +
labs(title = "Distribution of Simulated Means by Simulation Sizes", 
       y = "", 
       x = "Simulated Mean",
       subtitle = "Frequency"
       ) +
theme_bw() + 
theme_minimal()

```

-   I can use annotations

This code is from challenge 3, question 2. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors.

```{r}
#| label: dvs-3-2

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level,
                     fill = SET_level
                     )
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 

```

-   I can be creative...

The first code is from challenge 3, question 2. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors. The second code chunk is from challenge 2, spicy. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors.

```{r}
#| label: dvs-3-3

# Code 1

ggplot(data = teacher_evals_compare, 
       mapping = aes(x = sen_level,
                     fill = SET_level
                     )
       ) +
  geom_bar(stat = "count",
           position = "stack"
           ) + 
  scale_fill_manual(values = c("#c51b8a",
                               "#fa9fb5"
                               )
                    ) +
  theme_bw() +
  labs(x = "Seniority of Instructor", 
       y = "", 
       title = "Number of Sections", 
       fill = "SET Level"
       ) +
  geom_text(stat = "count", 
            mapping = aes(label = SET_level),     
            color = "white",                
            size = 3, 
            vjust = 2
            ) +
  theme(legend.position = "none") 

# Code 2

library(ggridges)

ggplot(data = surveys, 
       mapping = aes(x = weight,
        y = species, 
        stat = "density_ridges",
        position = "points_sina",
        fill = species
                    )
       ) +
  geom_density_ridges() + 
  labs(x = "Weight (in grams)" , 
     y = "", 
     subtitle = "Species of Rodents",
     title = "Density Ridge Plots of Weights of Various Rodent Species") +
 scale_fill_manual(values = c("torridus" = "#c51b8a", 
                              "spectabilis" = "#fa9fb5", 
                              "penicillatus" = "#f03b20", 
                              "ordii" = "#feb24c", 
                              "merriami" = "#fff7bc", 
                              "megalotis" = "#edf8b1",
                              "maniculatus" =  "#a1d99b",
                              "leucogaster" = "#e5f5f9", 
                              "hispidus" = "#7fcdbb", 
                              "fulvescens" = "#2b8cbe", 
                              "flavus" = "#e7e1ef", 
                              "eremicus" = "#bcbddc", 
                              "baileyi" = "#756bb1", 
                              "albigula" = "#8856a7"
                              )
                   ) +
    theme(legend.position = "none")

```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

This code is from lab 3, question 6.

```{r}
#| label: dvs-4-summarize

teacher_evals_clean |> 
  summarize(courses = n_distinct(course_id), 
            instructors = n_distinct(teacher_id)
            )

```

-   Example using `across()`

This code is from lab 7, question 1.

```{r}
#| label: dvs-4-across

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

This code is from lab 9, question 7. I used the website, <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3>, for my colors. *I originally labeled the title "Simulated Means By Sample Size" instead of "Simulated Mean of Means By Sample Size" and each column, "Simulated Mean of \_ " instead of "Simulated Mean of \_ Means." I now realize that this is not the simulated means but the simulated means of means. It is important that I correctly label all aspects of my table to ensure viewers correctly interpret my table and there are no misunderstandings about what the data represents.*

```{r}
#| label: dvs-5-1

library(gt)

all_simulations |> 
  group_by(n) |> 
  summarize(mean = mean(simulated_means),
            .groups = "drop"
            ) |> 
  pivot_wider(id_cols = everything(), 
              names_from = n, 
              values_from = mean) |> 
  rename('Simulated Mean of 10' = '10',
         'Simulated Mean of 100' = '100', 
         'Simulated Mean of 1,000' = '1000',
         'Simulated Mean of 10,000' = '10000'
         ) |> 
  gt() |> 
  tab_header(title = "Simulated Means By Sample Size", 
             subtitle = "Exploration of Results Across Varying Sample Sizes"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body()
            )

```

-   Example 2

This code is from lab 4, question 4

```{r}
#| label: dvs-5-2

mhi_region <- ca_childcare |> 
  select(region, 
         study_year, 
         mhi_2018 
         ) |> 
  filter(study_year %in% c(2008, 
                           2018
                           )
         ) |> 
  group_by(region, study_year) |>
  summarize(median_household_income = median(mhi_2018),
            .groups = "drop") |>
  pivot_wider(names_from = study_year,
              values_from = median_household_income,
              names_prefix = "Median Household Income in ") |> 
  arrange(desc(`Median Household Income in 2008`), 
          desc(`Median Household Income in 2018`)
          ) |>
  rename("Region" = region) |>
  print()

```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   Example 1

This code is from lab 9, question 7.I used <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3> to get my colors. *I originally labeled the title "Simulated Means By Sample Size" instead of "Simulated Mean of Means By Sample Size" and each column, "Simulated Mean of\_ " instead of "Simulated Mean of \_ Means." I now realize that this is not the simulated means but the simulated means of means. It is important that I correctly label all aspects of my table to ensure viewers correctly interpret my table and there are no misunderstandings about what the data represents.*

```{r}
#| label: dvs-6-1

library(gt)

all_simulations |> 
  group_by(n) |> 
  summarize(mean = mean(simulated_means),
            .groups = "drop"
            ) |> 
  pivot_wider(id_cols = everything(), 
              names_from = n, 
              values_from = mean) |> 
  rename('Simulated Mean of 10 Means' = '10',
         'Simulated Mean of 100 Means' = '100', 
         'Simulated Mean of 1,000 Means' = '1000',
         'Simulated Mean of 10,000 Means' = '10000'
         ) |> 
  gt() |> 
  tab_header(title = "Simulated Mean of Means By Sample Size", 
             subtitle = "Exploration of Results Across Varying Sample Sizes"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body()
            )

```

-   Example 2

This code is from lab 9, question 2.. I used <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3> to get my colors. *I originally used the names_prefix() function to add a prefix to the names of my columns, but these names were not the strongest names to describe the context of the columns. Instead, I used the rename() function to add stronger descriptive names for each column. Originally, I also included both the counts and proportions. I removed the counts as this was unnecessary and redundant.*

```{r}
#| label: dvs-6-2

library(gt)

tibble_of_results <- enframe(results, 
                             name = "simulation_number",
                             value = "ncorrect"
                             )

random_babies_table <- tibble_of_results |> 
  count(ncorrect, 
        name = "baby_count") |> 
  mutate(proportion = baby_count / sum(baby_count))

rotate_proportions <- random_babies_table |> 
  select(ncorrect, 
         proportion
         ) |> 
  pivot_wider(names_from = ncorrect, 
              values_from = proportion
                ) |>
  rename("0 Correct Matches" = "0",
         "1 Correct Match" = "1", 
         "2 Correct Matches" = "2", 
         "4 Correct Matches" = "4") |>
   gt() |> 
  tab_header(title = "Baby Matching Simulation Results", 
             subtitle = "Proportions of Correctly Matched Babies Across 10,000 Simulations"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body() 
            ) |>
  print()

```

**DVS-7: I show creativity in my tables.**

-   Example 1

This code is from lab 9, question 2.. I used <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3> to get my colors. *I originally used the names_prefix() function to add a prefix to the names of my columns, but these names were not the strongest names to describe the context of the columns. Instead, I used the rename() function to add stronger descriptive names for each column. Originally, I also included both the counts and proportions. I removed the counts as this was unnecessary and redundant.*

```{r}
#| label: dvs-7-1

library(gt)

tibble_of_results <- enframe(results, 
                             name = "simulation_number",
                             value = "ncorrect"
                             )

random_babies_table <- tibble_of_results |> 
  count(ncorrect, 
        name = "baby_count") |> 
  mutate(proportion = baby_count / sum(baby_count))

rotate_proportions <- random_babies_table |> 
  select(ncorrect, 
         proportion
         ) |> 
  pivot_wider(names_from = ncorrect, 
              values_from = proportion
                ) |>
  rename("0 Correct Matches" = "0",
         "1 Correct Match" = "1", 
         "2 Correct Matches" = "2", 
         "4 Correct Matches" = "4") |>
   gt() |> 
  tab_header(title = "Baby Matching Simulation Results", 
             subtitle = "Proportions of Correctly Matched Babies Across Simulations"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body() 
            ) |>
  print()

```

-   Example 2

This code is from lab 9, question 7. I used <https://colorbrewer2.org/#type=sequential&scheme=Oranges&n=3> to get my colors. *I originally labeled the title "Simulated Means By Sample Size" instead of "Simulated Mean of Means By Sample Size" and each column, "Simulated Mean of \_" instead of "Simulated Mean of \_ Means." I now realize that this is not the simulated means but the simulated means of means. It is important that I correctly label all aspects of my table to ensure viewers correctly interpret my table and there are no misunderstandings about what the data represents.*

```{r}
#| label: dvs-7-2

library(gt)

all_simulations |> 
  group_by(n) |> 
  summarize(mean = mean(simulated_means),
            .groups = "drop"
            ) |> 
  pivot_wider(id_cols = everything(), 
              names_from = n, 
              values_from = mean) |> 
  rename('Simulated Mean of 10 Means' = '10',
         'Simulated Mean of 100 Means' = '100', 
         'Simulated Mean of 1,000 Means' = '1000',
         'Simulated Mean of 10,000 Means' = '10000'
         ) |> 
  gt() |> 
  tab_header(title = "Simulated Mean of Means By Sample Size", 
             subtitle = "Exploration of Results Across Varying Sample Sizes"
             ) |> 
  tab_options(table.font.size = "18", 
              column_labels.font.size = "15", 
              heading.title.font.size = "25", 
              table.background.color = "#f0f0f0", 
              table.border.bottom.color = "#636363", 
              table.font.names = "Times New Roman"
              ) |>
 fmt_number(decimals = 3) |>
  tab_style(style = list(cell_borders(sides = "all",
                                      color= "black"
                                      ),
                         cell_fill(color = "white")
                         ),
            locations = cells_body()
            )

```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

This code is from lab 5, section 1: Crime Scene Report.

```{r}
#| label: pe-1-one-call

crime_scene_report |> 
  mutate(date = ymd(date)) |> 
  filter(date == ymd("2018-01-15"), 
         type == "murder",
         city == "SQL City"
         )

```

-   `across()`

This code is from lab 7, question 1.

```{r}
#| label: pe-1-across

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

```

-   `map()` functions

This code is from lab 8, question 4.

```{r}
#| label: pe-1-map-1

tibble(Variable = names(fish), 
       Missing = map_int(fish, 
                         ~ sum(is.na(.x)
                               )
                         )
       ) |> 
  rename(`Missing Amount` = Missing, 
         `Fish Attributes` = Variable) |>
  knitr::kable() |>
  kableExtra::kable_styling(font_size = 15)

```

**PE-2: I can write functions to reduce repetition in my code.**

-   Function that operates on vectors

This code is from lab 7, question 4

```{r}
#| label: pe-2-1

rescale_01 <- function(x) {
  if(!is.numeric(x)) stop("Input vector must be numeric.")
  if(length(x) <= 1) stop("Input vector requires more than one element.")
  range_1 <- range(x,
        na.rm = TRUE
        )
  (x - range_1[1]) / (range_1[2] - range_1[1])
}

```

-   Function that operates on data frames

This code is from lab 8, question 1. *Originally, I used the tibble() function outside of my function. While this worked, this could lead to redundancy, as I would have to rewrite the tibble() function every time I wanted to create a tibble with the map_chr_func() function. By implementing the tibble() function directly in my map_chr_func() function, I improved the efficiency and readability of my code. This change helps prevent errors with manually rewriting the same code and creates a reusable function.*

```{r}
#| label: pe-2-2

map_chr_func <- function(df){
  typ <- map_chr(df,
                 class
                 )
  tibble(
    Variable = names(df),
    Type = typ
    ) |> 
      pivot_wider(names_from = Variable, 
                  values_from = Type
                  )
  
 }

```

**PE-3: I can use iteration to reduce repetition in my code.**

-   `across()`

This code is from lab 7, question 1.

```{r}
#| label: pe-3-across

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

```

-   `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

This code is from lab 8, question 1. *Originally, I used the tibble() function outside of my function. While this worked, this could lead to redundancy, as I would have to rewrite the tibble() function every time I wanted to create a tibble with the map_chr_func() function. By implementing the tibble() function directly in my map_chr_func() function, I improved the efficiency and readability of my code. This change helps prevent errors with manually rewriting the same code and creates a reusable function.*

```{r}
#| label: pe-3-map-1

map_chr_func <- function(df){
  typ <- map_chr(df,
                 class
                 )
  tibble(
    Variable = names(df),
    Type = typ
    ) |> 
      pivot_wider(names_from = Variable, 
                  values_from = Type
                  )
  
 }

```

-   `map()` function with **more than one** input (e.g., `map_2()` or `pmap()`)

This code is from lab 9, questions 4-6.

```{r}
#| label: pe-3-map-2

simulate_means <- function(n, df){
  map_dbl(.x = 1: n, 
          .f = ~rchisq(n = 100, df = df) %>% mean()
          )
}

grid <- crossing(n = c(10,
                       100,
                       1000,
                       10000
                       ), 
                 df = 10)

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, 
                                          df = df
                                          ), 
                                .f = simulate_means)
         ) |> 
  unnest(simulated_means) 

```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

This code is from lab 7, question 1.

```{r}
#| label: pe-4-1

missing_values <- fish |> 
  summarise(across(.cols = trip:species, 
           .fns = ~ sum(is.na(.)),
           .names = "{.col}_na"
                  )
           ,
    na_observations = sum(if_any(everything(),
                                 is.na
                                 )
                          )
    ) |>
  print()

```

-   I can connect a data wrangling pipeline into a `ggplot()`

This code is from lab 4, question 6.

```{r}
#| label: pe-4-2

library(scales)
library(RColorBrewer)

custom <-colorRampPalette(brewer.pal(8, "Accent"))(10)

ca_childcare |>
  select(study_year,
         mc_infant,
         mc_toddler,
         mc_preschool,
         region
         ) |>
  rename(Infant = mc_infant, 
         Toddler = mc_toddler,
         Preschool = mc_preschool
         ) |> 
  pivot_longer(cols = c("Infant",
                       "Toddler", 
                       "Preschool"
                       ), 
               names_to = "age", 
               values_to = "median_income"
               ) |> 
  mutate(fct_relevel(age, "Infant",
                          "Toddler",
                          "Preschool")
        ) |>
  drop_na() |>
  ggplot(mapping = aes(x = study_year,
                          y = median_income,
                          color = fct_reorder2(region,
                                               study_year,
                                               median_income
                                               )
                          )
       ) +
  geom_point(size = 0.5) + 
  geom_smooth() + 
  facet_wrap(~ age) +  
  labs(title = "Weekly Median Price for Center-Based Childcare ($)",
       x = "Study Year",
       y = "",
       color = "California Region"
       ) +
  scale_x_continuous(breaks = seq(2008,
                                  2018, 
                                  by = 2,
                                  )
                     ) + 
  scale_y_continuous(breaks = c(100,
                                200,
                                300,
                                400,
                                500
                                ), 
                     limits = c(100,
                                500
                                )
                     ) +
  scale_color_manual(values = custom) +
  theme_bw() + 
  theme(aspect.ratio = 1, 
        axis.text.x = element_text(size = 6), 
        legend.title = element_text(size = 8),   
        legend.text = element_text(size = 8), 
        title = element_text(size = 8)
        )

```

## Data Simulation & Statisical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

This code is from lab 9, question 1. *Originally, I used \$ operators to get correct_baby_count, but realized I could use the summarize() function here instead. By using the summarize() function instead of the \$ operator, my code more closely follows the tidyverse guidelines. This esures that my code is readable, clear, and efficient.*

```{r}
#| label: dsm-1-1 

randomBabies <- function(nBabies){
   babies <- tibble(baby = 1: nBabies, 
                    parent = sample(1: nBabies,
                                    size = nBabies,
                                    replace = FALSE
                                    )
   )         
  correct_baby_count <- sum(babies$baby == babies$parent)
  return(correct_baby_count)

}

results <- map_int(.x = 1:10000, 
                   .f = ~ randomBabies(nBabies = 4))

head(results)

```

-   Example 2

This code is from lab 9, questions 4-6.

```{r}
#| label: dsm-1-2

simulate_means <- function(n, df){
  map_dbl(.x = 1: n, 
          .f = ~rchisq(n = 100, df = df) %>% mean()
          )
}

grid <- crossing(n = c(10,
                       100,
                       1000,
                       10000
                       ), 
                 df = 10)

all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n = n, 
                                          df = df
                                          ), 
                                .f = simulate_means)
         ) |> 
  unnest(simulated_means) 


```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

This code is from challenge 3, questions 1 and 3.

```{r}
#| label: dsm-2-1

teacher_evals <- read_csv(here("data", "teacher_evals.csv"))

teacher_evals_compare <- teacher_evals |> 
  filter(question_no == 903) |> 
  mutate(SET_level = if_else(SET_score_avg >= 4,
                             "excellent",
                             "standard"
                             ), 
         sen_level = if_else(seniority <= 4,
                              "junior",
                              "senior"
                              )
          
         ) |>
  select(course_id, 
         SET_level, 
         sen_level
         )

chi_square_test <- chisq.test(teacher_evals_compare$SET_level, 
                              teacher_evals_compare$sen_level
                              )

print(chi_square_test)


```

-   Example 2

This code is from lab 4, question 8.

```{r}
#| label: dsm-2-2

species_mod <- aov(formula = weight ~species_id, 
  data = surveys
                )

summary(species_mod)

```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

After receiving feedback on labs, I submitted revisions with reflections for all labs where revisions were accepted, dedicating significant time to understanding my mistakes, correcting them, and enhancing the efficiency of my code. As someone without much coding experience prior to this course, learning how to use R has been a constructively challenging experience. Working through lab assignments has provided me with the opportunity to struggle through material, enhancing my critical thinking and tangible coding skills. Through feedback, I have learned where I was not fully grasping a concept or where I could make my code more efficient. With this feedback, I was able to explore the content more deeply and consider new and different approaches to coding problems.

For each problem I received a growing on or problems where I received a success but still received feedback, when I completed my revision and reflection, I truly sat with the material, considering the importance of the changes I was implementing.I made sure to consider and explain why it was important to fix or include what I added in my revision. For example, in lab 3, I initially saved unnecessary objects or created new data frames and did not display the results of my code in the quarto document. I did not originally see this as an issue when working on the lab assignment. However, once I received feedback on this aspect of my lab, I became aware of the issue in my lab. I realized I needed to consider when it is necessary and beneficial to save objects and create data frames and when it is unnecessary, a concept I had not considered before. I also realized that my reader was unable to see the results of my code often. I then considered and reflected on the fact that I was not providing the necessary information to the reader of my quarto document for them to be able to understand and follow my lab, and therefore my reader was not able to interpret and understand information about the data. Another pivotal revision was for lab 4, question 6, where I was asked to recreate Dr. Theobold's plot showing the change over time of fill time median price for center-based childcare for infants, toddlers, and preschoolers. Upon my first submission, I received a growing with ample feedback. I spent considerable time learning how to properly use the forcats, RColorBrewer, and ggplot2 packages to figure out how to incorporate various aspects to my visualization including correctly releveling my variables, incorporating colors, and adding elements to my visualizations theme. I have included my reflection below for this revision as I believe this is a strong reflection that accurately exemplifies my commitment to revising my thinking throughout this quarter. Overall, through revisions and reflections such as these, I gained insight into efficient coding practices and ensuring my coding serves its intended and appropriate purpose.

**Reflection for Lab 4, Question 6:**

Originally, I attempted to recreate this plot, but missed a few of the key aspects that make this visualization clear and effective. Firstly, I incorporated the rename() function to rename the variables, mc_infant, mc_toddler, and mc_preschool to Infant, Toddler, and Preschool so that they would match Dr.Theobolds. This ensures that the labels in the facts represent the content of the visualization rather than just the original variable names in the data frame, which dont provide meaningful context on their own. Secondly, I used the mutate() and fct_relevel() functions to change the order of the levels so that they are in order of age, with Infant on the left, Toddler in the middle, and Preschool on the right. This is beneficial because it ensures the plot follows a logical progression, from youngest to oldest. Then, I used the theme() function to resize aspects of my visualization. This included using the aspect.ratio() function to make the facets proportional. This helped to spread out my squished text on the axes, making the values on my axes much more readable and clear. I also used the theme() function to resize the title of my visualization and the text in my legend. All of these changes to the text made my visualization more readable. I also used the scale_y_continuous() function to add values to my y-axis because there were only values 200, 300, and 400 and I felt it was beneficial to include 100 and 500 to provide a broader range of values, ensuring the axis is visually representative. I also made a custom color palette using the colorRampPalette() and the scale_color_manual() function to reorder the colors in the legend so they appear in the same order as the lines in the plot. This adds to making my visualization more easy to interpret. Lastly, I incorporated theme_bw() to apply a black and white theme to my plot, matching Dr.Theobolds theme. I also used the scale_color_brewer() function to add the Accent palette to match Dr.Theobolds colors on their visualization. These two changes make the visualization visually appealing and professional looking. Overall, these changes were important to incorporate because they enhanced the clarity, professional appearance, and readability of the visualization.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

Throughout this course, I have challenged myself by attempting challenge problems, sometimes struggling through them and not always getting them perfectly right. When I received feedback, I made sure to revise these as it was important to me to push myself to deepen my understanding and enhance my coding skills through these more complex tasks. I personally also felt challenged by many problems within the lab assignments and spent considerable time thinking out problems and multiple ways of coding to solve these problems.

In my portfolio, I have included code from Challenge 2,3, and 9, exemplifying the ways in which I pushed myself to learn new skills and tools. In challenge 2, I created a density ridge plot and added custom colors for each ridge. Learning how to use the scales_fill_manual() function was a beneficial tool as I was able to use this in future assignments to make my visualizations aesthetically appealing and helpful for the viewer's interpretation of information. In challenge 3, I was provided with a plot and instructed to write code to recreate this plot. This is a great example of a problem I attempted and succeeded at, yet found difficult and had to work through. This task required me to work backwards and consider all of the components needed to create the plot. I found this problem challenging initially, but this struggle was part of the learning experience, ultimately deepening my understanding of making visualizations in R. Lastly, I included code from Challenge 9, where I incorporated the scales_fill_manual() function to many of my plots and tables in Lab 8 and 9. In this challenge, I also learned how to use the knitr and gt package to format my plots and tables nicely and incorporate alterations including changing font and font size, adding titles and subtitles, and adding cell borders. Overall, these challenges pushed me to learn new skills that I was able to then incorporate in future labs to make my code and visualizations more complex and advanced.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

Each week, I completed my peer review to provide feedback to my peers on the tidiness and efficiency of their code. I always made sure to acknowledge where my peers had strong, tidy and efficient code as well as providing constructive feedback in a respectful manner, suggesting areas where they could enhance the tidiness and efficiency of their code.

**Here is an example of peer feedback I provided to a classmate for their Lab 2:**

Question 1 - Correctly loaded the R packages needed for your analysis\
Question 2 - Correctly used the here() package to load in the data\
Question 3 - You used the glimpse() function to provide a brief overview of the dataset which was a great way to display information about your dataset. However, in your description of the data, you said the dataset contains about 8015 students. Although there are 8015 rows, each row does not correlate to an individual student. If you look at the first three columns, this provides information on what each row represents.\
Question 4 - Each row represents one question from the SET questionnaire for each class section for a specific teacher. I would make sure to include this aspect because this is a crucial aspect of what differentiates each row.\
Question 5 - Your code looks really great in this question. One thing you could do to tidy up your code is in your select() line, you could make a new line after each comma.\
Question 6 - Your code looks great and provides the information you need! If you wanted to, you could make this code into one chunk of code!\
Question 7 - Your code provides the instructor and course with missing values.\
Question 8 - I like that you chose to include a barchart to show the demographics of the instructors in the study!\
Question 9 - The code you wrote looks great! You might want to tidy it up a little bit by making a new line after commas\
Question 10 - Your code looks great!\
Question 11 - Your code looks great!\
Question 12 - Your code looks great!

**Here is an example of peer feedback I provided to a classmate for their lab 5:**

Tidy code  - Your code is very tidy overall! You make sure to include whitespaces when necessary and use new lines after majority of commas and after using the pipe operator. There were a few times in your code chunks where you could make a new line after a comma. For example, for this line of code in step 3:

filter(ymd(check_in_date) == ymd(20180109),
gender == "male",
membership_status == "gold",
str_detect(membership_id, "\^48Z"),
str_detect(plate_number, "H42W"))\

You could change it so that there are new lines after each comma like this:
filter(ymd(check_in_date) == ymd(20180109),
gender == "male",
membership_status == "gold",
str_detect(membership_id,
		"\^48Z"
			),
str_detect(plate_number,
	"H42W"
			)
	)\

Also, when doing this, you can line up your opening and closing parentheses. This makes it easier for the reader of your code to see what parentheses are connected and what they are enclosing. Besides these little aspects to your code, it looks very tidy and easy to read! \

Efficient Code - You do a great job at using functions for multiple tasks so that you dont have to repeat yourself in your code. For example, you use the filter() function to filter a data set in multiple ways. You do this well in step 2, 3, and 5. Additionally, you use the left_join at some points in your code, but could use inner_join instead to increase efficiency. Although it is producing the correct results, using inner_join would only keep the rows where there is a match in both datasets so that you dont end up with rows with multiple NAs, making the results more precise to what you want since you are trying to narrow down data sets. This also makes your code more efficient.

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

During weekly pair programming activities, I feel I was always able to be patient and respectful, ensuring my partner's input was valued. I made it a priority to listen as the coder to create a collaborative environment where I respected my partners perspective and learned from their ideas and coding approaches. Sometimes my partner would share an approach to solving a task that was not how I initially thought to approach the task. I was open minded to their ideas during these moments and appreciated the opportunity to learn an alternative way to solve a problem. Although I had some difficulties communicating when I felt my voice wasnt being heard during one week's programming activity, I became more confident in redirecting focus the following week to maintain our respective roles and improve our collaboration.
